from bs4 import BeautifulSoup
import json
import random
import os
import boto3
import requests
from io import BytesIO
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ AWS ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
AWS_REGION = os.getenv("AWS_DEFAULT_REGION")
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME")
S3_FOLDER = os.getenv("S3_FOLDER")

# Boto3 S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
s3_client = boto3.client(
    "s3",
    aws_access_key_id=AWS_ACCESS_KEY_ID,
    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
    region_name=AWS_REGION
)

# HTML íŒŒì¼ ê²½ë¡œ
input_file = "/Users/soop/s0obang/í•™ë¶€ì—°êµ¬ìƒ24w/RagWithChatbot/input_job.txt"
output_file = "/Users/soop/s0obang/í•™ë¶€ì—°êµ¬ìƒ24w/RagWithChatbot/output_job.json"  # ë³€í™˜ëœ JSON ë°ì´í„°ë¥¼ ì €ì¥í•  íŒŒì¼

def download_and_upload_image(image_url):
    """ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•œ í›„ S3ì— ì—…ë¡œë“œí•˜ê³  S3 URL ë°˜í™˜"""
    if not image_url:
        print("ì´ë¯¸ì§€ URLì´ None. ì—…ë¡œë“œ ê±´ë„ˆëœ€.")
        return None

    try:
        #ì´ë¯¸ì§€ ë‹¤ìš´
        response = requests.get(image_url, stream=True)
        if response.status_code != 200:
            print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {image_url} (ì‘ë‹µ ì½”ë“œ: {response.status_code})")
            return None

        image_data = BytesIO(response.content)  # ë©”ëª¨ë¦¬ ë‚´ì—ì„œ íŒŒì¼ì²˜ëŸ¼ ë‹¤ë£¨ê¸°

        #íŒŒì¼ í™•ì¥ì ì²˜ë¦¬ (ì—†ìœ¼ë©´ jpg)
        file_extension = image_url.split(".")[-1].split("?")[0] if "." in image_url else "jpg"
        s3_filename = f"{S3_FOLDER}{random.randint(1000, 9999)}.{file_extension}"  # S3 íŒŒì¼ ê²½ë¡œ ì§€ì •

        #S3ì— ì—…ë¡œë“œ
        s3_client.upload_fileobj(image_data, S3_BUCKET_NAME, s3_filename, ExtraArgs={'ACL': 'public-read'})

        #ì—…ë¡œë“œëœ íŒŒì¼ì˜ S3 URL ìƒì„±
        s3_url = f"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{s3_filename}"
        print(f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„±ê³µ: {s3_url}")
        return s3_url

    except Exception as e:
        print(f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# HTML ë°ì´í„°ë¥¼ ì½ê³  ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ”
with open(input_file, "r", encoding="utf-8") as f:
    html_blocks = f.read().split("\n\n")  # ì—”í„°(ì¤„ë°”ê¿ˆ)ë¡œ êµ¬ë¶„ëœ HTML ë¸”ë¡

# JSON ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
articles = []

# HTML ë¸”ë¡ì„ ìˆœíšŒí•˜ë©° íŒŒì‹±
for html_data in html_blocks:
    if not html_data.strip():  # ë¹ˆ ì¤„ì€ ë¬´ì‹œ
        continue

    soup = BeautifulSoup(html_data, "html.parser")

    # ê²Œì‹œë¬¼ ë°ì´í„° ì¶”ì¶œ
    for article in soup.find_all("article", class_="item"):
        title = article.find("h2", class_="large").text.strip()
        create_time = article.find("time", class_="large").text.strip()
        content = article.find("p", class_="large").text.strip()

        # ì²¨ë¶€ ì´ë¯¸ì§€ ì¶”ì¶œ (í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ ê°œ ì²˜ë¦¬)
        image_urls = []
        attach_images = article.find("div", class_="attaches")

        if attach_images:
            #ì´ë¯¸ì§€ê°€ ì—¬ëŸ¬ ê°œ
            if "multiple" in attach_images.get("class", []):
                for img in attach_images.find_all("img"):
                    img_src = img.get("src")
                    if img_src:
                        print(f"ğŸ”¹ ë‹¤ì¤‘ ì´ë¯¸ì§€ URL ì°¾ìŒ: {img_src}")
                        uploaded_url = download_and_upload_image(img_src)
                        if uploaded_url:
                            image_urls.append(uploaded_url)
                        else:
                            print(f"âš ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {img_src}")

            #ì´ë¯¸ì§€ í•˜ë‚˜ì¼ê²½ìš°
            elif "full" in attach_images.get("class", []):
                img_tag = attach_images.find("img")
                if img_tag:
                    img_src = img_tag.get("src")
                    if img_src:
                        print(f"ğŸ”¹ ë‹¨ì¼ ì´ë¯¸ì§€ URL ì°¾ìŒ: {img_src}")
                        uploaded_url = download_and_upload_image(img_src)
                        if uploaded_url:
                            image_urls.append(uploaded_url)
                        else:
                            print(f"âš ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {img_src}")
                else:
                    print("âš ï¸ `img` íƒœê·¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ì—…ë¡œë“œ ê±´ë„ˆëœ€.")

        #ëŒ“ê¸€
        comments = [comment.text.strip() for comment in article.find_all("p", class_="large")][1:]

        # JSON í˜•íƒœë¡œ ë°ì´í„° ì¶”ê°€
        articles.append({
            "title": title,
            "create": create_time,
            "content": content,
            "imageUrls": image_urls,
            "comments": comments
        })

# ê¸°ì¡´ JSON íŒŒì¼ ì½ê¸° (íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ê¸°ì¡´ ë°ì´í„° ìœ ì§€)
if os.path.exists(output_file):
    with open(output_file, "r", encoding="utf-8") as f:
        try:
            existing_data = json.load(f)
        except json.JSONDecodeError:
            existing_data = []
else:
    existing_data = []

# ìƒˆë¡œìš´ ë°ì´í„° ì¶”ê°€ í›„ JSON ì €ì¥
existing_data.extend(articles)

with open(output_file, "w", encoding="utf-8") as f:
    json.dump(existing_data, f, ensure_ascii=False, indent=4)

print(f"âœ… ë³€í™˜ ì™„ë£Œ! JSON ë°ì´í„°ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
